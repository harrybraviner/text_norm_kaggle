{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path # if you haven't already done so\n",
    "file = Path(os.getcwd()).resolve()\n",
    "parent, root = file.parent, file.parents[1]\n",
    "sys.path.append(str(parent))\n",
    "import data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/en_train.csv', 'rt')\n",
    "f.readline();\n",
    "data = [data_cleaning.split_line(l) for l in f]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of each category\n",
    "cc = set([l[2] for l in data])\n",
    "dd = {x:0 for x in cc}\n",
    "for t in [l[2] for l in data]: dd[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of all characters in input\n",
    "char_set = {}\n",
    "for l in data:\n",
    "    l = l[3]\n",
    "    xs = set(l)\n",
    "    for x in xs:\n",
    "        if x in char_set:\n",
    "            char_set[x] +=1\n",
    "        else:\n",
    "            char_set[x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in char_set if char_set[x] >= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in data:\n",
    "    output_chars = [x for x in set(l[4]) if not (data_cleaning.is_simple_char(x) or x in [' ', '\\''])]\n",
    "    input_chars = set(l[3])\n",
    "    if any([c not in input_chars for c in output_chars]):\n",
    "        print('Input: {}\\nOutput: {}\\nType: {}\\n'.format(l[3], l[4], l[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of all characters in output\n",
    "output_char_set = {}\n",
    "for l in data:\n",
    "    l = l[4]\n",
    "    xs = set(l)\n",
    "    for x in xs:\n",
    "        output_char_set[x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_file = open('all_chars.txt', 'rt')\n",
    "char_string = char_file.readline()\n",
    "char_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test is character is CJK (see https://stackoverflow.com/questions/30069846/how-to-find-out-chinese-or-japanese-character-in-a-string-in-python)\n",
    "def is_cjk(char):\n",
    "\n",
    "    ranges = [\n",
    "      {\"from\": ord(u\"\\u3300\"), \"to\": ord(u\"\\u33ff\")},         # compatibility ideographs\n",
    "      {\"from\": ord(u\"\\ufe30\"), \"to\": ord(u\"\\ufe4f\")},         # compatibility ideographs\n",
    "      {\"from\": ord(u\"\\uf900\"), \"to\": ord(u\"\\ufaff\")},         # compatibility ideographs\n",
    "      {\"from\": ord(u\"\\U0002F800\"), \"to\": ord(u\"\\U0002fa1f\")}, # compatibility ideographs\n",
    "      {\"from\": ord(u\"\\u30a0\"), \"to\": ord(u\"\\u30ff\")},         # Japanese Kana\n",
    "      {\"from\": ord(u\"\\u2e80\"), \"to\": ord(u\"\\u2eff\")},         # cjk radicals supplement\n",
    "      {\"from\": ord(u\"\\u4e00\"), \"to\": ord(u\"\\u9fff\")},\n",
    "      {\"from\": ord(u\"\\u3400\"), \"to\": ord(u\"\\u4dbf\")},\n",
    "      {\"from\": ord(u\"\\U00020000\"), \"to\": ord(u\"\\U0002a6df\")},\n",
    "      {\"from\": ord(u\"\\U0002a700\"), \"to\": ord(u\"\\U0002b73f\")},\n",
    "      {\"from\": ord(u\"\\U0002b740\"), \"to\": ord(u\"\\U0002b81f\")},\n",
    "      {\"from\": ord(u\"\\U0002b820\"), \"to\": ord(u\"\\U0002ceaf\")}  # included as of Unicode 8.0\n",
    "    ]\n",
    "\n",
    "    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([c for c in char_string if is_cjk(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cjk_chars = [c for c in char_string if not is_cjk(c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_chars = [c for c in char_string if data_cleaning.is_simple_char(c) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_char_counts = [len(set([c for c in l[3] if data_cleaning.is_vanilla_char(c) == False])) for l in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(complex_char_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1.0 if c > 0 else 0.0 for c in complex_char_counts]) / len(complex_char_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
